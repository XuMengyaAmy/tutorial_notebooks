{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "cifar10_TrustScore.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/XuMengyaAmy/tutorial_notebooks/blob/main/cifar10_TrustScore.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eQ87J3fmDxjE"
      },
      "source": [
        "# CIFAR10:\n",
        "Original CIFAR10 [0: airplane, 1: automobile, 2: bird, 3: cat, 4: deer, 5: dog, 6: frog, 7: horse, 8: ship, 9: truck] <br>\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ny77mwOy5rwX"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "import torchvision\n",
        "from torchvision import models\n",
        "import torchvision.transforms as transforms\n",
        "import os\n",
        "import argparse\n",
        "import copy\n",
        "import random\n",
        "import numpy as np\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "def seed_everything(seed=12):\n",
        "    random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "    np.random.seed(seed)\n",
        "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "parser = argparse.ArgumentParser(description='BalancedLSF Training')\n",
        "parser.add_argument('--lr', default=0.1, type=float, help='learning rate')\n",
        "parser.add_argument('--lr_schedule', default=0, type=int, help='lr scheduler')\n",
        "parser.add_argument('--batch_size', default=1024, type=int, help='batch size')\n",
        "parser.add_argument('--test_batch_size', default=2048, type=int, help='batch size')\n",
        "parser.add_argument('--num_epoch', default=1, type=int, help='epoch number')\n",
        "parser.add_argument('--num_classes', type=int, default=10, help='number classes')\n",
        "args = parser.parse_args(args=[])\n",
        "\n",
        "def train(model, trainloader, criterion, optimizer):\n",
        "    model.train()\n",
        "    for batch_idx, (inputs, targets) in enumerate(trainloader):\n",
        "        inputs, targets = inputs.to(device), targets.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, targets)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "def test(model, testloader):\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for batch_idx, (inputs, targets) in enumerate(testloader):\n",
        "            inputs, targets = inputs.to(device), targets.to(device)\n",
        "            outputs = model(inputs)\n",
        "            _, predicted = outputs.max(1)\n",
        "            total += targets.size(0)\n",
        "            correct += predicted.eq(targets).sum().item()\n",
        "    return correct / total"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LZ9xCxgxhmsn"
      },
      "source": [
        "Training"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "seed_everything()\n",
        "mean_cifar10, std_cifar10 = (0.5071, 0.4866, 0.4409), (0.2009, 0.1984, 0.2023)\n",
        "transform_train = transforms.Compose([transforms.RandomCrop(32, padding=4),\n",
        "            transforms.RandomHorizontalFlip(), transforms.ToTensor(),\n",
        "            transforms.Normalize(mean_cifar10, std_cifar10), ])\n",
        "transform_test = transforms.Compose([transforms.ToTensor(),\n",
        "    transforms.Normalize(mean_cifar10, std_cifar10),])\n",
        "train_dataset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform_train)\n",
        "test_dataset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform_test)\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=args.batch_size, shuffle=True,num_workers=2)\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=2048, shuffle=False, num_workers=2)\n",
        "\n",
        "model = models.resnet18().to(device)\n",
        "model.fc = nn.Linear(model.fc.in_features, args.num_classes)\n",
        "model = model.to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ylEr5myINLRG",
        "outputId": "583c2c1e-e9c9-40bd-bf42-9d506fae56c3"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## This cell can be ignored if you wanna use the trained weights from next cell"
      ],
      "metadata": {
        "id": "J3SzNoN6-n0y"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wsei6ouF6IXy",
        "outputId": "b774c6a7-ef95-4649-8f07-ade22013fb2c"
      },
      "source": [
        "\n",
        "optimizer = optim.SGD(model.parameters(), lr=args.lr, momentum=0.9, nesterov=False, weight_decay=0.0001)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "best_epoch, best_acc = 0.0, 0\n",
        "for epoch in range(args.num_epoch):\n",
        "    train(model, train_loader, criterion, optimizer)\n",
        "    accuracy = test(model, test_loader)\n",
        "    if accuracy > best_acc:\n",
        "        patience = 0\n",
        "        best_acc = accuracy\n",
        "        best_epoch = epoch\n",
        "        best_model = copy.deepcopy(model)\n",
        "        torch.save(best_model.state_dict(), 'best_model_cifar10_lt.pth.tar')\n",
        "    print('epoch: {}  acc: {:.4f}  best epoch: {}  best acc: {:.4f}'.format(\n",
        "            epoch, accuracy, best_epoch, best_acc, optimizer.param_groups[0]['lr']))"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch: 0  acc: 0.3273  best epoch: 0  best acc: 0.3273\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Download trained model"
      ],
      "metadata": {
        "id": "byghfr0qOBkI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U -q PyDrive\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "# Authenticate and create the PyDrive client.\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)\n",
        "\n",
        "id = ['1rDyWMpo1RYa9wFx5gZsXf_mHMwCTr2oz']\n",
        "downloaded = drive.CreateFile({'id':id[0]}) \n",
        "downloaded.GetContentFile('best_model_cifar10_lt.pth.tar')"
      ],
      "metadata": {
        "id": "FRUd5P0JOBBM"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## confusion matrix: scratch"
      ],
      "metadata": {
        "id": "kWXG58TvNcUB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "\n",
        "def get_confusion_matrix(model, testloader):\n",
        "    model.eval()\n",
        "    confusion_matrix = torch.zeros(args.num_classes, args.num_classes)\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    acc_per_class = torch.zeros(args.num_classes)\n",
        "    samples_per_class = torch.zeros(args.num_classes)\n",
        "    with torch.no_grad():\n",
        "        for i, (inputs, targets) in enumerate(testloader):\n",
        "            inputs, targets = inputs.to(device), targets.to(device)\n",
        "            outputs = model(inputs)\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "            for t, p in zip(targets.view(-1), preds.view(-1)):\n",
        "                    confusion_matrix[t.long(), p.long()] += 1\n",
        "            \n",
        "            total += targets.size(0)\n",
        "            correct_matrix = preds.eq(targets)\n",
        "            correct += correct_matrix.sum().item()\n",
        "            for cls in range (args.num_classes):\n",
        "                acc_per_class[cls] += correct_matrix[targets==cls].sum().item()\n",
        "                samples_per_class[cls] += (targets==cls).sum().item()\n",
        "\n",
        "    return correct / total, confusion_matrix, acc_per_class/samples_per_class\n",
        "\n",
        "def get_tp_tn_fp_fn(conf_matrix, nb_classes):\n",
        "    TP = conf_matrix.diag()\n",
        "    for c in range(nb_classes):\n",
        "        idx = torch.ones(nb_classes).byte()\n",
        "        idx[c] = 0\n",
        "        # all non-class samples classified as non-class\n",
        "        TN = conf_matrix[idx.nonzero()[:, None], idx.nonzero()].sum() #conf_matrix[idx[:, None], idx].sum() - conf_matrix[idx, c].sum()\n",
        "        # all non-class samples classified as class\n",
        "        FP = conf_matrix[idx, c].sum()\n",
        "        # all class samples not classified as class\n",
        "        FN = conf_matrix[c, idx].sum()\n",
        "        \n",
        "        print('Class {}\\nTP {}, TN {}, FP {}, FN {}, acc={}, recall={}, prec={}, total= {}'.format(\n",
        "            c, TP[c], TN, FP, FN,(TP[c]+TN)/(TP[c]+TN+FP+FN), TP[c]/(TP[c]+FN), TP[c]/(TP[c]+FP), (TP[c]+TN+FP+FN) ))\n",
        "    \n",
        "\n",
        "model.load_state_dict(torch.load('best_model_cifar10_lt.pth.tar'))\n",
        "acc, confusion_matrix, acc_per_class = get_confusion_matrix(model, test_loader)\n",
        "print('confusion matrix:\\n', confusion_matrix)\n",
        "class_wise_acc = confusion_matrix.diag()/confusion_matrix.sum(1)\n",
        "print('per-class accuracy from CM:', class_wise_acc)\n",
        "print('per-class accuracy from scratch:', acc_per_class)\n",
        "print('accuracy-with CM:',class_wise_acc.mean(), ',directly:',acc)\n",
        "\n",
        "get_tp_tn_fp_fn(confusion_matrix, args.num_classes)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yLHhlr2w_6jx",
        "outputId": "737e4059-a907-4d3d-edc3-45d46868c15b"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "confusion matrix:\n",
            " tensor([[855.,   6.,  44.,  11.,   9.,   3.,   6.,   4.,  43.,  19.],\n",
            "        [ 22., 905.,   7.,   5.,   1.,   1.,   3.,   0.,  16.,  40.],\n",
            "        [ 28.,   1., 841.,  24.,  43.,  13.,  29.,   9.,   6.,   6.],\n",
            "        [ 20.,   3., 109., 666.,  33.,  65.,  49.,  28.,  10.,  17.],\n",
            "        [ 12.,   1.,  62.,  60., 752.,   8.,  45.,  53.,   5.,   2.],\n",
            "        [ 12.,   0.,  96., 203.,  33., 579.,  19.,  46.,   7.,   5.],\n",
            "        [  4.,   4.,  41.,  50.,  15.,   8., 870.,   3.,   3.,   2.],\n",
            "        [ 15.,   1.,  44.,  44.,  20.,  10.,   1., 848.,   6.,  11.],\n",
            "        [ 43.,  12.,   8.,   8.,   3.,   1.,   5.,   2., 908.,  10.],\n",
            "        [ 39.,  48.,   7.,   5.,   0.,   2.,   5.,   2.,  20., 872.]])\n",
            "per-class accuracy from CM: tensor([0.8550, 0.9050, 0.8410, 0.6660, 0.7520, 0.5790, 0.8700, 0.8480, 0.9080,\n",
            "        0.8720])\n",
            "per-class accuracy from scratch: tensor([0.8550, 0.9050, 0.8410, 0.6660, 0.7520, 0.5790, 0.8700, 0.8480, 0.9080,\n",
            "        0.8720])\n",
            "accuracy-with CM: tensor(0.8096) ,directly: 0.8096\n",
            "Class 0\n",
            "TP 855.0, TN 8805.0, FP 195.0, FN 145.0, acc=0.9660000205039978, recall=0.8550000190734863, prec=0.8142856955528259, total= 10000.0\n",
            "Class 1\n",
            "TP 905.0, TN 8924.0, FP 76.0, FN 95.0, acc=0.9829000234603882, recall=0.9049999713897705, prec=0.9225280284881592, total= 10000.0\n",
            "Class 2\n",
            "TP 841.0, TN 8582.0, FP 418.0, FN 159.0, acc=0.942300021648407, recall=0.8410000205039978, prec=0.6679904460906982, total= 10000.0\n",
            "Class 3\n",
            "TP 666.0, TN 8590.0, FP 410.0, FN 334.0, acc=0.925599992275238, recall=0.6660000085830688, prec=0.6189591288566589, total= 10000.0\n",
            "Class 4\n",
            "TP 752.0, TN 8843.0, FP 157.0, FN 248.0, acc=0.9595000147819519, recall=0.7519999742507935, prec=0.827282726764679, total= 10000.0\n",
            "Class 5\n",
            "TP 579.0, TN 8889.0, FP 111.0, FN 421.0, acc=0.9467999935150146, recall=0.5789999961853027, prec=0.8391304612159729, total= 10000.0\n",
            "Class 6\n",
            "TP 870.0, TN 8838.0, FP 162.0, FN 130.0, acc=0.97079998254776, recall=0.8700000047683716, prec=0.8430232405662537, total= 10000.0\n",
            "Class 7\n",
            "TP 848.0, TN 8853.0, FP 147.0, FN 152.0, acc=0.9700999855995178, recall=0.8479999899864197, prec=0.8522613048553467, total= 10000.0\n",
            "Class 8\n",
            "TP 908.0, TN 8884.0, FP 116.0, FN 92.0, acc=0.979200005531311, recall=0.9079999923706055, prec=0.88671875, total= 10000.0\n",
            "Class 9\n",
            "TP 872.0, TN 8888.0, FP 112.0, FN 128.0, acc=0.9760000109672546, recall=0.871999979019165, prec=0.8861788511276245, total= 10000.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:36: UserWarning: indexing with dtype torch.uint8 is now deprecated, please use a dtype torch.bool instead. (Triggered internally at  ../aten/src/ATen/native/IndexingUtils.h:30.)\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:38: UserWarning: indexing with dtype torch.uint8 is now deprecated, please use a dtype torch.bool instead. (Triggered internally at  ../aten/src/ATen/native/IndexingUtils.h:30.)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# TrustScore"
      ],
      "metadata": {
        "id": "ZXuzwbLggqlA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.neighbors import KDTree, KNeighborsClassifier\n",
        "\n",
        "\n",
        "class TrustScore:\n",
        "    \"\"\"\n",
        "    Trust Score: a measure of classifier uncertainty based on nearest neighbors.\n",
        "  \"\"\"\n",
        "\n",
        "    def __init__(self, k=10, alpha=0.0, filtering=\"none\", min_dist=1e-12):\n",
        "        \"\"\"\n",
        "        k and alpha are the tuning parameters for the filtering,\n",
        "        filtering: method of filtering. option are \"none\", \"density\",\n",
        "        \"uncertainty\"\n",
        "        min_dist: some small number to mitigate possible division by 0.\n",
        "    \"\"\"\n",
        "        self.k = k\n",
        "        self.filtering = filtering\n",
        "        self.alpha = alpha\n",
        "        self.min_dist = min_dist\n",
        "\n",
        "    def filter_by_density(self, X: np.array):\n",
        "        \"\"\"Filter out points with low kNN density.\n",
        "    Args:\n",
        "    X: an array of sample points.\n",
        "    Returns:\n",
        "    A subset of the array without points in the bottom alpha-fraction of\n",
        "    original points of kNN density.\n",
        "    \"\"\"\n",
        "        kdtree = KDTree(X)\n",
        "        knn_radii = kdtree.query(X, k=self.k)[0][:, -1]\n",
        "        eps = np.percentile(knn_radii, (1 - self.alpha) * 100)\n",
        "        return X[np.where(knn_radii <= eps)[0], :]\n",
        "\n",
        "    def filter_by_uncertainty(self, X: np.array, y: np.array):\n",
        "        \"\"\"Filter out points with high label disagreement amongst its kNN neighbors.\n",
        "    Args:\n",
        "    X: an array of sample points.\n",
        "    Returns:\n",
        "    A subset of the array without points in the bottom alpha-fraction of\n",
        "    samples with highest disagreement amongst its k nearest neighbors.\n",
        "    \"\"\"\n",
        "        neigh = KNeighborsClassifier(n_neighbors=self.k)\n",
        "        neigh.fit(X, y)\n",
        "        confidence = neigh.predict_proba(X)\n",
        "        cutoff = np.percentile(confidence, self.alpha * 100)\n",
        "        unfiltered_idxs = np.where(confidence >= cutoff)[0]\n",
        "        return X[unfiltered_idxs, :], y[unfiltered_idxs]\n",
        "\n",
        "    def fit(self, X: np.array, y: np.array):\n",
        "        \"\"\"Initialize trust score precomputations with training data.\n",
        "    WARNING: assumes that the labels are 0-indexed (i.e.\n",
        "    0, 1,..., n_labels-1).\n",
        "    Args:\n",
        "    X: an array of sample points.\n",
        "    y: corresponding labels.\n",
        "    \"\"\"\n",
        "\n",
        "        self.n_labels = np.max(y) + 1\n",
        "        self.kdtrees = [None] * self.n_labels\n",
        "        if self.filtering == \"uncertainty\":\n",
        "            X_filtered, y_filtered = self.filter_by_uncertainty(X, y)\n",
        "        for label in range(self.n_labels):\n",
        "            if self.filtering == \"none\":\n",
        "                X_to_use = X[np.where(y == label)[0]]\n",
        "                self.kdtrees[label] = KDTree(X_to_use)\n",
        "            elif self.filtering == \"density\":\n",
        "                X_to_use = self.filter_by_density(X[np.where(y == label)[0]])\n",
        "                self.kdtrees[label] = KDTree(X_to_use)\n",
        "            elif self.filtering == \"uncertainty\":\n",
        "                X_to_use = X_filtered[np.where(y_filtered == label)[0]]\n",
        "                self.kdtrees[label] = KDTree(X_to_use)\n",
        "\n",
        "            if len(X_to_use) == 0:\n",
        "                print(\n",
        "                    \"Filtered too much or missing examples from a label! Please lower \"\n",
        "                    \"alpha or check data.\"\n",
        "                )\n",
        "\n",
        "    def get_score(self, X: np.array, y_pred: np.array):\n",
        "        \"\"\"Compute the trust scores.\n",
        "    Given a set of points, determines the distance to each class.\n",
        "    Args:\n",
        "    X: an array of sample points.\n",
        "    y_pred: The predicted labels for these points.\n",
        "    Returns:\n",
        "    The trust score, which is ratio of distance to closest class that was not\n",
        "    the predicted class to the distance to the predicted class.\n",
        "    \"\"\"\n",
        "        d = np.tile(None, (X.shape[0], self.n_labels))\n",
        "        for label_idx in range(self.n_labels):\n",
        "            d[:, label_idx] = self.kdtrees[label_idx].query(X, k=2)[0][:, -1]\n",
        "\n",
        "        sorted_d = np.sort(d, axis=1)\n",
        "        d_to_pred = d[range(d.shape[0]), y_pred]\n",
        "        d_to_closest_not_pred = np.where(\n",
        "            sorted_d[:, 0] != d_to_pred, sorted_d[:, 0], sorted_d[:, 1]\n",
        "        )\n",
        "        return d_to_closest_not_pred / (d_to_pred + self.min_dist)\n",
        "\n",
        "\n",
        "class KNNConfidence:\n",
        "    \"\"\"Baseline which uses disagreement to kNN classifier.\n",
        "  \"\"\"\n",
        "\n",
        "    def __init__(self, k=10):\n",
        "        self.k = k\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        self.kdtree = KDTree(X)\n",
        "        self.y = y\n",
        "\n",
        "    def get_score(self, X, y_pred):\n",
        "        knn_idxs = self.kdtree.query(X, k=self.k)[1]\n",
        "        knn_outputs = self.y[knn_idxs]\n",
        "        return np.mean(\n",
        "            knn_outputs == np.transpose(np.tile(y_pred, (self.k, 1))), axis=1\n",
        "        )\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "JtlgZtWGQr18"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Validate on trustscore (V1):"
      ],
      "metadata": {
        "id": "cmc5xUpyqNqd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def fit_trust_model(trust_model, testloader):\n",
        "    with torch.no_grad():\n",
        "        for batch_idx, (inputs, targets) in enumerate(testloader):\n",
        "            inputs_array = np.array(inputs.view(inputs.shape[0], -1).cpu())\n",
        "            targets_array = np.array(targets.cpu())\n",
        "            trust_model.fit(inputs_array, targets_array)\n",
        "        \n",
        "    return trust_model\n",
        "\n",
        "def test_trust_score(model, trust_model, testloader):\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    trust_score_all = []\n",
        "    with torch.no_grad():\n",
        "        for batch_idx, (inputs, targets) in enumerate(testloader):\n",
        "            inputs, targets = inputs.to(device), targets.to(device)\n",
        "            outputs = model(inputs)\n",
        "            _, predicted = outputs.max(1)\n",
        "            total += targets.size(0)\n",
        "            correct += predicted.eq(targets).sum().item()\n",
        "\n",
        "            # ========= Get Trust Score ============ #\n",
        "            inputs_array = np.array(inputs.view(inputs.shape[0], -1).cpu())\n",
        "            predicted_array = np.array(predicted.cpu())\n",
        "            trust_score = trust_model.get_score(inputs_array, predicted_array)\n",
        "            trust_score_all.extend(trust_score)\n",
        "        \n",
        "        acc = correct / total \n",
        "    return acc, trust_score_all\n",
        "\n",
        "trust_model = TrustScore()\n",
        "trust_model = fit_trust_model(trust_model, test_loader)\n",
        "\n",
        "model.load_state_dict(torch.load('best_model_cifar10_lt.pth.tar'))\n",
        "acc, trust_score_all = test_trust_score(model, trust_model, test_loader)\n",
        "print('Accuracy:', acc)\n",
        "print('Trust Score for First 2 Samples:',trust_score_all[:2] )\n"
      ],
      "metadata": {
        "id": "niX10vjcmVdv",
        "outputId": "07f3a943-8be7-49c7-d737-60813a12eff8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.8096\n",
            "Trust Score for First 2 Samples: [0.9062759867500153, 1.0645652828689323]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Validate on trustscore (V2):"
      ],
      "metadata": {
        "id": "scDZVZkXqW1u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_data_processed(testloader):\n",
        "    with torch.no_grad():\n",
        "        inputs_array_all = []\n",
        "        targets_array_all = []\n",
        "        for batch_idx, (inputs, targets) in enumerate(testloader):\n",
        "            inputs_array = np.array(inputs.view(inputs.shape[0], -1).cpu())\n",
        "            targets_array = np.array(targets.cpu())\n",
        "            inputs_array_all.extend(inputs_array)\n",
        "            targets_array_all.extend(targets_array)\n",
        "\n",
        "        return inputs_array_all, targets_array_all\n",
        "\n",
        "def test_trust_score(model, trust_model, testloader):\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    trust_score_all = []\n",
        "    with torch.no_grad():\n",
        "        for batch_idx, (inputs, targets) in enumerate(testloader):\n",
        "            inputs, targets = inputs.to(device), targets.to(device)\n",
        "            outputs = model(inputs)\n",
        "            _, predicted = outputs.max(1)\n",
        "            total += targets.size(0)\n",
        "            correct += predicted.eq(targets).sum().item()\n",
        "\n",
        "            # ========= Get Trust Score ============ #\n",
        "            inputs_array = np.array(inputs.view(inputs.shape[0], -1).cpu())\n",
        "            predicted_array = np.array(predicted.cpu())\n",
        "            trust_score = trust_model.get_score(inputs_array, predicted_array)\n",
        "            trust_score_all.extend(trust_score)\n",
        "        \n",
        "        acc = correct / total \n",
        "    return acc, trust_score_all\n",
        "\n",
        "\n",
        "trust_model = TrustScore()\n",
        "inputs_array_all, targets_array_all = get_data_processed(test_loader)\n",
        "print('Processed data:',np.array(inputs_array_all).shape, np.array(targets_array_all).shape)\n",
        "trust_model.fit(np.array(inputs_array_all), np.array(targets_array_all))\n",
        "\n",
        "model.load_state_dict(torch.load('best_model_cifar10_lt.pth.tar'))\n",
        "acc, trust_score_all = test_trust_score(model, trust_model, test_loader)\n",
        "print('Accuracy:', acc)\n",
        "print('Trust Score for First 2 Samples:',trust_score_all[:2] )"
      ],
      "metadata": {
        "id": "xdmLgU3mqfPD",
        "outputId": "792aed62-730e-4150-80ba-c03322e86b09",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 400
        }
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed data: (10000, 3072) (10000,)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-7b195b004bac>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'best_model_cifar10_lt.pth.tar'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m \u001b[0macc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrust_score_all\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_trust_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrust_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Accuracy:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0macc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Trust Score for First 2 Samples:'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrust_score_all\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-9-7b195b004bac>\u001b[0m in \u001b[0;36mtest_trust_score\u001b[0;34m(model, trust_model, testloader)\u001b[0m\n\u001b[1;32m     27\u001b[0m             \u001b[0minputs_array\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m             \u001b[0mpredicted_array\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredicted\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m             \u001b[0mtrust_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrust_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs_array\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredicted_array\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m             \u001b[0mtrust_score_all\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrust_score\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-7-094f55ecd13d>\u001b[0m in \u001b[0;36mget_score\u001b[0;34m(self, X, y_pred)\u001b[0m\n\u001b[1;32m     90\u001b[0m         \u001b[0md\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mlabel_idx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m             \u001b[0md\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_idx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkdtrees\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlabel_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m         \u001b[0msorted_d\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Trust Score V4 (most correct one) \n",
        "pass train loader to .fit(), and prepare all test dataset firstly, then compute the score for entire dataset."
      ],
      "metadata": {
        "id": "gvjdgCVl4Ptv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_data_processed(trainloader):\n",
        "    with torch.no_grad():\n",
        "        inputs_array_all = []\n",
        "        targets_array_all = []\n",
        "        for batch_idx, (inputs, targets) in enumerate(trainloader):\n",
        "            inputs_array = np.array(inputs.view(inputs.shape[0], -1).cpu())\n",
        "            targets_array = np.array(targets.cpu())\n",
        "            inputs_array_all.extend(inputs_array)\n",
        "            targets_array_all.extend(targets_array)\n",
        "\n",
        "        return inputs_array_all, targets_array_all\n",
        "def test_data_processed(model, testloader):\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    inputs_array_all = []\n",
        "    predicted_array_all = []\n",
        "    with torch.no_grad():\n",
        "        for batch_idx, (inputs, targets) in enumerate(testloader):\n",
        "            inputs, targets = inputs.to(device), targets.to(device)\n",
        "            outputs = model(inputs)\n",
        "            _, predicted = outputs.max(1)\n",
        "            total += targets.size(0)\n",
        "            correct += predicted.eq(targets).sum().item()\n",
        "\n",
        "            inputs_array = np.array(inputs.view(inputs.shape[0], -1).cpu())\n",
        "            inputs_array_all.extend(inputs_array)\n",
        "\n",
        "            predicted_array = np.array(predicted.cpu())\n",
        "            predicted_array_all.extend(predicted_array)\n",
        "\n",
        "        acc = correct / total \n",
        "    return acc, inputs_array_all, predicted_array_all\n",
        "\n",
        "trust_model = TrustScore()\n",
        "inputs_array_all, targets_array_all = get_data_processed(train_loader)\n",
        "print('Processed data:',np.array(inputs_array_all).shape, np.array(targets_array_all).shape) # images-targets pair\n",
        "trust_model.fit(np.array(inputs_array_all), np.array(targets_array_all)) # To learn the extra trust model based on the train loader first\n",
        "\n",
        "model.load_state_dict(torch.load('best_model_cifar10_lt.pth.tar'))\n",
        "# prepare entire test images and entire predicted labels first\n",
        "acc, test_inputs_array_all, test_predicted_array_all = test_data_processed(model,test_loader)\n",
        "print('Process test data', np.array(test_inputs_array_all).shape, np.array(test_predicted_array_all).shape)# images-predicted label pair\n",
        "trust_score_all = trust_model.get_score(np.array(test_inputs_array_all), np.array(test_predicted_array_all))\n",
        "print('Accuracy:', acc)\n",
        "print('Trust Score for First 2 Samples:',trust_score_all[:2] )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k5wxeU_34Ovb",
        "outputId": "b3722f10-c3a6-4d60-a9ca-eab6fe184828"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed data: (50000, 3072) (50000,)\n",
            "Process test data (10000, 3072) (10000,)\n"
          ]
        }
      ]
    }
  ]
}